{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8265afc3-b209-4047-b328-1016f836022d",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3187938-d76e-48cf-a043-bbe2eb6cae7b",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0691982d-fe73-47ce-92b4-a2c31693a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14688\\551341022.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from PIL import Image, ImageTk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from keras.models import load_model\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ebb24-dfe1-4d47-97fe-e5bae00c1e50",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d44bdce-df4c-4ce4-a1a4-3bbd260dad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "labels = []\n",
    "total_files = 0  # Track the total number of files processed\n",
    "\n",
    "for dirname, _, filenames in os.walk('./kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        label = filename.split('_')[-1]\n",
    "        label = label.split('.')[0]\n",
    "        labels.append(label.lower())\n",
    "        total_files += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242fb018-4b0f-4716-ba45-01b5e83ae166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./kaggle/input\\Dataset\\angry\\01_angry.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./kaggle/input\\Dataset\\angry\\02_angry.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./kaggle/input\\Dataset\\angry\\03_angry.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./kaggle/input\\Dataset\\angry\\04_angry.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./kaggle/input\\Dataset\\angry\\05_angry.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      speech  label\n",
       "0  ./kaggle/input\\Dataset\\angry\\01_angry.wav  angry\n",
       "1  ./kaggle/input\\Dataset\\angry\\02_angry.wav  angry\n",
       "2  ./kaggle/input\\Dataset\\angry\\03_angry.wav  angry\n",
       "3  ./kaggle/input\\Dataset\\angry\\04_angry.wav  angry\n",
       "4  ./kaggle/input\\Dataset\\angry\\05_angry.wav  angry"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe\n",
    "df = pd.DataFrame()\n",
    "df['speech'] = paths\n",
    "df['label'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55cdd7-6868-44e8-852b-af28224a85c3",
   "metadata": {},
   "source": [
    "## Loading The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07132540-27cc-4f1b-8c73-f43625ca1fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = load_model('trained_model.h5')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Define the path to save the dataset\n",
    "dataset_file = 'dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d98b6-097f-4a33-a3a7-b55e3334c103",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699e025-2f34-4a43-97d8-83b2c9eb9ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
     ]
    }
   ],
   "source": [
    "# Function to predict emotion\n",
    "def predict_emotion(audio_file):\n",
    "    y, sr = librosa.load(audio_file, duration=3, offset=0.5)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    mfcc = np.expand_dims(mfcc, axis=0)\n",
    "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(mfcc)\n",
    "    \n",
    "    # Get predicted emotion label\n",
    "    emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'ps']\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_emotion = emotion_labels[predicted_index]\n",
    "    \n",
    "    # If the model is uncertain, prompt the user for the emotion label\n",
    "    if predicted_emotion == 'neutral':\n",
    "        manual_label = input(\"Please enter the emotion for this file (angry, disgust, fear, happy, neutral, sad): \")\n",
    "        predicted_emotion = manual_label.lower()\n",
    "    \n",
    "    return predicted_index, predicted_emotion, y, sr, prediction\n",
    "\n",
    "# Function to handle file selection\n",
    "def select_file():\n",
    "    global df  # Declare df as a global variable\n",
    "    global total_files  # Declare total_files as a global variable\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Audio files\", \"*.wav\")])\n",
    "    if file_path:\n",
    "        predicted_index, predicted_emotion, y, sr, prediction = predict_emotion(file_path)\n",
    "        emoji = get_emoji(predicted_index)\n",
    "        result_label.config(text=f\"{emoji}\\n{predicted_emotion}\", font=(\"Arial\", 36), fg=get_color(predicted_emotion))\n",
    "        \n",
    "        # Add the file to the dataset\n",
    "        new_row = {'speech': file_path, 'label': predicted_emotion}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        df.to_csv(dataset_file, index=False)  # Save updated dataset to file\n",
    "        \n",
    "        # Increment total files processed\n",
    "        total_files += 1\n",
    "        \n",
    "        # Save file to emotion-related folder\n",
    "        save_file_with_emotion(file_path, predicted_emotion)\n",
    "        \n",
    "        # Plot waveform and spectrogram\n",
    "        plot_audio_data(y, sr, predicted_emotion)\n",
    "        \n",
    "        # Plot bar chart\n",
    "        plot_bar_chart(prediction)\n",
    "\n",
    "# Function to plot waveform and spectrogram\n",
    "def plot_audio_data(data, sr, emotion):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    # Waveform\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(np.arange(len(data)) / sr, data)\n",
    "    plt.title('Waveform')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "    # Spectrogram\n",
    "    plt.subplot(2, 1, 2)\n",
    "    x = librosa.stft(data)\n",
    "    xdb = librosa.amplitude_to_db(abs(x))\n",
    "    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Convert matplotlib figure to Tkinter-compatible image\n",
    "    waveform_img = plt_to_image(plt.gcf())\n",
    "    \n",
    "    # Display waveform image\n",
    "    waveform_label.config(image=waveform_img)\n",
    "    waveform_label.image = waveform_img  # Keep a reference to avoid garbage collection\n",
    "    \n",
    "    \n",
    "# Function to plot bar chart\n",
    "def plot_bar_chart(prediction):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'ps']\n",
    "    plt.bar(emotion_labels, prediction[0])\n",
    "    plt.title('Emotion Probabilities')\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    # Convert matplotlib figure to Tkinter-compatible image\n",
    "    bar_chart_img = plt_to_image(plt.gcf())\n",
    "\n",
    "    # Display bar chart image\n",
    "    bar_chart_label.config(image=bar_chart_img)\n",
    "    bar_chart_label.image = bar_chart_img  # Keep a reference to avoid garbage collection\n",
    "\n",
    "# Function to convert matplotlib figure to image\n",
    "def plt_to_image(figure):\n",
    "    figure.canvas.draw()\n",
    "    img_data = np.array(figure.canvas.renderer.buffer_rgba())\n",
    "    img = Image.fromarray(img_data)\n",
    "    img = ImageTk.PhotoImage(image=img)\n",
    "    return img\n",
    "\n",
    "# Function to get emoji based on predicted index\n",
    "def get_emoji(predicted_index):\n",
    "    emojis = ['😠', '😟', '😨', '😄', '😐', '😔', '😶']\n",
    "    return emojis[predicted_index]\n",
    "\n",
    "# Function to get color based on predicted emotion\n",
    "def get_color(predicted_emotion):\n",
    "    colors = {'angry': 'red', 'disgust': 'green', 'fear': 'purple', 'happy': 'orange', 'neutral': 'black', 'sad': 'blue', 'ps': 'cyan'}\n",
    "    return colors.get(predicted_emotion, 'black')\n",
    "\n",
    "# Function to save file into emotion-related folder\n",
    "def save_file_with_emotion(file_path, emotion):\n",
    "    save_folder = f\"./kaggle/input/New_Dataset/{emotion}/\"  # Update this path based on folder structure\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    destination_path = os.path.join(save_folder, file_name)\n",
    "    os.rename(file_path, destination_path)\n",
    "    print(f\"File saved into '{save_folder}' folder.\")\n",
    "\n",
    "# Create the tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "\n",
    "# Create a label for displaying the result\n",
    "result_label = tk.Label(root, text=\"Please select an audio file.\", wraplength=400, font=(\"Arial\", 36))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Create labels for waveform and bar chart\n",
    "waveform_label = tk.Label(root)\n",
    "waveform_label.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "bar_chart_label = tk.Label(root)\n",
    "bar_chart_label.pack(side=tk.RIGHT, padx=10, pady=10)\n",
    "\n",
    "# Create a button for file selection\n",
    "select_button = tk.Button(root, text=\"Select Audio File\", command=select_file)\n",
    "select_button.pack(pady=10)\n",
    "\n",
    "# Run the tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a5c1af5-4bd3-4449-bee2-9b4bb99376b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files processed: 4567\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total files processed: {total_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb36903-1e21-457d-b2eb-b67ccf494c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
